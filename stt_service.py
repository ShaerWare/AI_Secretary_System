#!/usr/bin/env python3
"""
–°–µ—Ä–≤–∏—Å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω–∞ –±–∞–∑–µ Whisper
"""
import torch
import whisper
from faster_whisper import WhisperModel
import logging
from pathlib import Path
from typing import Optional, Union
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class STTService:
    def __init__(
        self,
        model_size: str = "medium",
        use_faster_whisper: bool = True,
        device: str = "auto"
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Ä–≤–∏—Å–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏

        Args:
            model_size: –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (tiny, base, small, medium, large)
            use_faster_whisper: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å faster-whisper (–±—ã—Å—Ç—Ä–µ–µ)
            device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (auto, cuda, cpu)
        """
        self.model_size = model_size
        self.use_faster_whisper = use_faster_whisper

        if device == "auto":
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device

        logger.info(f"üéß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è STT Service –Ω–∞ {self.device}")
        logger.info(f"üìä –ú–æ–¥–µ–ª—å: {model_size}")

        try:
            if use_faster_whisper:
                # Faster Whisper - –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
                self.model = WhisperModel(
                    model_size,
                    device=self.device,
                    compute_type="float16" if self.device == "cuda" else "int8"
                )
                logger.info("‚úÖ Faster Whisper –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            else:
                # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π Whisper
                self.model = whisper.load_model(model_size, device=self.device)
                logger.info("‚úÖ OpenAI Whisper –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise

    def transcribe(
        self,
        audio_path: Union[str, Path],
        language: str = "ru"
    ) -> dict:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ä–µ—á—å –∏–∑ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞

        Args:
            audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            language: –Ø–∑—ã–∫ —Ä–µ—á–∏

        Returns:
            dict —Å –ø–æ–ª—è–º–∏: text, language, segments
        """
        logger.info(f"üé§ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ: {audio_path}")

        try:
            if self.use_faster_whisper:
                segments, info = self.model.transcribe(
                    str(audio_path),
                    language=language,
                    vad_filter=True,  # Voice Activity Detection
                    vad_parameters=dict(min_silence_duration_ms=500)
                )

                # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                text_segments = []
                for segment in segments:
                    text_segments.append({
                        "start": segment.start,
                        "end": segment.end,
                        "text": segment.text.strip()
                    })

                full_text = " ".join([s["text"] for s in text_segments])

                result = {
                    "text": full_text,
                    "language": info.language,
                    "segments": text_segments
                }

            else:
                result_whisper = self.model.transcribe(
                    str(audio_path),
                    language=language,
                    fp16=(self.device == "cuda")
                )

                result = {
                    "text": result_whisper["text"].strip(),
                    "language": result_whisper["language"],
                    "segments": result_whisper.get("segments", [])
                }

            logger.info(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: '{result['text'][:100]}...'")
            return result

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            raise

    def transcribe_audio_data(
        self,
        audio_data: np.ndarray,
        sample_rate: int = 16000,
        language: str = "ru"
    ) -> dict:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ä–µ—á—å –∏–∑ numpy array

        Args:
            audio_data: –ê—É–¥–∏–æ –¥–∞–Ω–Ω—ã–µ
            sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
            language: –Ø–∑—ã–∫

        Returns:
            dict —Å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        """
        import tempfile
        import soundfile as sf

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            sf.write(tmp.name, audio_data, sample_rate)
            result = self.transcribe(tmp.name, language)

        Path(tmp.name).unlink()  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        return result


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    service = STTService(model_size="base", use_faster_whisper=True)

    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    # result = service.transcribe("test_audio.wav")
    # print(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {result['text']}")
